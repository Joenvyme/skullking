# ğŸ”’ SÃ©curitÃ© et ContrÃ´le des CoÃ»ts OpenAI

## ğŸ›¡ï¸ Protections ImplÃ©mentÃ©es

### 1. Rate Limiting (Limite de RequÃªtes)

âœ… **DÃ©jÃ  implÃ©mentÃ©** dans `app/api/chat/route.ts`

- **20 requÃªtes par heure** par adresse IP
- Protection contre l'abus et les coÃ»ts excessifs
- Headers de rÃ©ponse pour informer l'utilisateur :
  - `X-RateLimit-Limit`: Limite totale
  - `X-RateLimit-Remaining`: RequÃªtes restantes
  - `X-RateLimit-Reset`: Heure de rÃ©initialisation

### 2. Limitation des Tokens

âœ… **DÃ©jÃ  implÃ©mentÃ©**

- Maximum **500 tokens par rÃ©ponse** (`maxTokens: 500`)
- Limite la longueur des rÃ©ponses pour rÃ©duire les coÃ»ts
- Limite la longueur des questions Ã  500 caractÃ¨res

### 3. Validation des EntrÃ©es

âœ… **DÃ©jÃ  implÃ©mentÃ©**

- VÃ©rification de la prÃ©sence des messages
- Validation de la longueur des questions
- VÃ©rification de la clÃ© API avant utilisation

## ğŸ’° Configuration des Limites de Budget OpenAI

### Sur platform.openai.com

1. Allez sur [platform.openai.com/account/billing/limits](https://platform.openai.com/account/billing/limits)
2. Configurez des **hard limits** (limites strictes) :
   - **Hard limit mensuel** : DÃ©finissez un montant maximum (ex: $10/mois)
   - **Hard limit par requÃªte** : Limitez le coÃ»t par requÃªte
   - **Alertes** : Configurez des alertes Ã  50%, 75%, 90% de votre budget

### Exemple de Configuration RecommandÃ©e

```
Budget mensuel : $10
Alerte Ã  50% : $5
Alerte Ã  75% : $7.50
Alerte Ã  90% : $9
Hard limit : $10 (arrÃªt automatique)
```

## ğŸ“Š Monitoring des CoÃ»ts

### 1. Dashboard OpenAI

Surveillez vos coÃ»ts en temps rÃ©el :
- [platform.openai.com/usage](https://platform.openai.com/usage)
- Voir les coÃ»ts par modÃ¨le
- Voir les coÃ»ts par jour/mois

### 2. Estimation des CoÃ»ts

Avec les limites actuelles :
- **20 requÃªtes/heure/IP**
- **500 tokens max par rÃ©ponse**
- **ModÃ¨le gpt-4o** (~$2.50 par 1M tokens d'entrÃ©e, ~$10 par 1M tokens de sortie)

**Estimation par requÃªte** :
- Question : ~50 tokens
- RÃ©ponse : ~500 tokens max
- CoÃ»t approximatif : **~$0.005 par requÃªte** (0.5 centime)

**Avec 20 requÃªtes/heure/IP** :
- CoÃ»t max par IP/heure : **~$0.10** (10 centimes)
- CoÃ»t max par IP/jour (si utilisÃ© 24h) : **~$2.40**
- CoÃ»t max par IP/mois : **~$72**

### 3. Variables d'Environnement pour Ajuster les Limites

CrÃ©ez un fichier `.env.local` avec :

```env
# Rate limiting
RATE_LIMIT_MAX_REQUESTS=20
RATE_LIMIT_WINDOW_HOURS=1

# Token limits
MAX_TOKENS_PER_RESPONSE=500
MAX_QUESTION_LENGTH=500
```

Puis modifiez `lib/api/rate-limit.ts` pour utiliser ces variables.

## ğŸš€ AmÃ©liorations pour la Production

### 1. Utiliser un Service de Rate Limiting DÃ©diÃ©

Pour la production, remplacez le rate limiting en mÃ©moire par :

- **Upstash Redis** (gratuit jusqu'Ã  10K requÃªtes/jour)
- **Vercel Edge Config** (si dÃ©ployÃ© sur Vercel)
- **Cloudflare Rate Limiting**

### 2. Authentification Utilisateur (Optionnel)

Pour limiter par utilisateur plutÃ´t que par IP :

```typescript
// Exemple avec authentification
const userId = await getUserId(req) // Votre systÃ¨me d'auth
const rateLimit = checkRateLimit(`user:${userId}`)
```

### 3. Caching des RÃ©ponses (Optionnel)

Cachez les rÃ©ponses frÃ©quentes pour Ã©viter les appels API :

```typescript
// Exemple avec cache
const cacheKey = `chat:${gameVersion}:${hashQuestion(userQuestion)}`
const cached = await cache.get(cacheKey)
if (cached) return cached
```

### 4. ModÃ¨le Moins Cher (Optionnel)

Pour rÃ©duire les coÃ»ts, utilisez un modÃ¨le moins cher :

```typescript
// Au lieu de gpt-4o, utilisez gpt-3.5-turbo
model: openaiModel('gpt-3.5-turbo', {
  apiKey: openaiApiKey,
})
```

**CoÃ»ts comparatifs** :
- `gpt-4o` : ~$2.50/$10 par 1M tokens (entrÃ©e/sortie)
- `gpt-3.5-turbo` : ~$0.50/$1.50 par 1M tokens (entrÃ©e/sortie)

## âš ï¸ Checklist Avant la Mise en Production

- [ ] âœ… Rate limiting configurÃ© (20 req/heure/IP)
- [ ] âœ… Limite de tokens configurÃ©e (500 tokens max)
- [ ] âœ… Hard limits configurÃ©s sur OpenAI (budget mensuel)
- [ ] âœ… Alertes configurÃ©es sur OpenAI (50%, 75%, 90%)
- [ ] âœ… Monitoring des coÃ»ts activÃ©
- [ ] âš ï¸ **Ã€ faire** : Tester le rate limiting
- [ ] âš ï¸ **Ã€ faire** : Configurer les hard limits sur OpenAI
- [ ] âš ï¸ **Optionnel** : ImplÃ©menter le caching
- [ ] âš ï¸ **Optionnel** : Passer Ã  un modÃ¨le moins cher si nÃ©cessaire

## ğŸ” Tester le Rate Limiting

Pour tester que le rate limiting fonctionne :

1. Faites 20 requÃªtes rapidement
2. La 21Ã¨me devrait retourner une erreur 429
3. Attendez 1 heure ou changez d'IP

## ğŸ“ Notes Importantes

1. **Le rate limiting actuel est en mÃ©moire** : Il sera rÃ©initialisÃ© Ã  chaque redÃ©marrage du serveur. Pour la production, utilisez Redis ou un service dÃ©diÃ©.

2. **Les limites sont par IP** : Un utilisateur peut contourner en changeant d'IP. Pour une meilleure protection, ajoutez l'authentification.

3. **Surveillez rÃ©guliÃ¨rement** : VÃ©rifiez vos coÃ»ts sur le dashboard OpenAI au moins une fois par semaine.

4. **Testez en staging** : Avant de mettre en production, testez avec de vraies requÃªtes pour estimer les coÃ»ts rÃ©els.

## ğŸ†˜ En Cas de DÃ©pense Excessive

Si vous remarquez des coÃ»ts anormaux :

1. **ArrÃªtez immÃ©diatement** le service
2. **VÃ©rifiez les logs** pour identifier l'abus
3. **RÃ©duisez les limites** dans `lib/api/rate-limit.ts`
4. **Activez les hard limits** sur OpenAI
5. **Contactez le support OpenAI** si nÃ©cessaire

